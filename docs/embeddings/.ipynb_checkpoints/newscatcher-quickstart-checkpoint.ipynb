{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7046ab5",
   "metadata": {},
   "source": [
    "# Quickstart (Localmode with Pinecone and Weaviate)\n",
    "\n",
    "## Requirements\n",
    "\n",
    "* Python 3.7+\n",
    "* `.env` file with one or both sets of credentials (visit [Pinecone](https://www.pinecone.io/) and/or [Weaviate](https://weaviate.io/) for instructions on creating an account and getting credentials):\n",
    "```\n",
    "# Pinecone\n",
    "\n",
    "PINECONE_PROJECT_ID=\n",
    "PINECONE_ENVIRONMENT=\n",
    "PINECONE_API_KEY=\n",
    "HUGGING_FACE_TOKEN=\n",
    "\n",
    "# Weaviate\n",
    "\n",
    "WEAVIATE_URL=\n",
    "WEAVIATE_API_KEY=\n",
    "```\n",
    "* [Topic Labeled News Dataset](https://www.kaggle.com/datasets/kotartemiy/topic-labeled-news-dataset)\n",
    "* Featureform installed:\n",
    "```shell\n",
    "pip install featureform\n",
    "```\n",
    "* Hugging Face [`sentence-transformers`](https://huggingface.co/sentence-transformers) installed:\n",
    "```\n",
    "pip install sentence-transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61a5e2",
   "metadata": {},
   "source": [
    "## Step  1. Register Provider and Source\n",
    "\n",
    "We'll be using Pinecone for this example, but you can also choose to use Weaviate.\n",
    "\n",
    "**NOTE:**\n",
    "Until `sep=\";\"` is a supported parameter in `register_file`,\n",
    "you'll need to preproces the dataset by doing the following:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"labelled_newscatcher_dataset.csv\", sep=\";\")\n",
    "df.to_csv(\"newscatcher_dataset.csv\", index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca4f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import featureform as ff\n",
    "from featureform import local\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv(\".env\")\n",
    "\n",
    "pinecone = ff.register_pinecone(\n",
    "    name=\"pinecone4\",\n",
    "    project_id=os.getenv(\"PINECONE_PROJECT_ID\", \"\"),\n",
    "    environment=os.getenv(\"PINECONE_ENVIRONMENT\", \"\"),\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\", \"\"),\n",
    ")\n",
    "\n",
    "news = local.register_file(\n",
    "    name=\"news\",\n",
    "    description=\"108,774 news articles labelled with 8 topics (balanced)\",\n",
    "    path=\"ucb-hackathon/newscatcher_dataset.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58895602",
   "metadata": {},
   "source": [
    "Now we'll create an instance of the Featureform client and apply the changes. We'll be using `client` after each step to apply our changes and checkpoint our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9732b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from featureform import Client\n",
    "\n",
    "client = Client(local=True)\n",
    "\n",
    "client.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a5eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!featureform list sources --local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d0b8f",
   "metadata": {},
   "source": [
    "## Step 2. Register Transformation\n",
    "\n",
    "Given the size of the Newscatcher dataset, we'll limit the context we'll create embeddings for to only science-related articles. Once we've filtered by the topic, we'll use [`all-MiniLM-L6-v2`](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) to create embeddings of the article titles so we can perform searches on them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2291505",
   "metadata": {},
   "outputs": [],
   "source": [
    "@local.df_transformation(inputs=[news])\n",
    "def vectorize_science_news(news_df):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    science_news = news_df[news_df[\"topic\"] == \"SCIENCE\"]\n",
    "\n",
    "    embeddings = model.encode(science_news[\"title\"].tolist())\n",
    "\n",
    "    science_news[\"title_embedding\"] = embeddings.tolist()\n",
    "\n",
    "    print(science_news)\n",
    "\n",
    "    return science_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47af2bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ba89e",
   "metadata": {},
   "source": [
    "## Step 3. Register Entity and Feature\n",
    "\n",
    "We'll now register an entity and a feature, which will kick off the materialization process.\n",
    "\n",
    "**NOTE:**\n",
    "This may take some time to complete. See the progress bar for status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8705af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ff.entity\n",
    "class NewsDomain:\n",
    "    science_news = ff.Embedding(\n",
    "        vectorize_science_news[[\"link\", \"title_embedding\"]],\n",
    "        dims=384,\n",
    "        vector_db=pinecone,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f593aa",
   "metadata": {},
   "source": [
    "## Step 4. Register On-Demand Feature\n",
    "\n",
    "We'll want to query the embeddings we created, and we can do so using Featureform's on-demand feature decorator. This creates a feature that's calculated on the client at serving time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db430da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ff.ondemand_feature(name=\"science_news_search\")\n",
    "def search_science_news(serving_client, params, entity):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    search_vector = model.encode(params[0])\n",
    "    feature, variant = params[1]\n",
    "\n",
    "    return serving_client.nearest(feature, variant, search_vector.tolist(), k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c54f0",
   "metadata": {},
   "source": [
    "## Step 5. Serve On-Demand Feature (i.e. Semantic Search)\n",
    "\n",
    "Now we'll query the vector database via our on-demand feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"asteroids over England\"\n",
    "embedding_feature_variant = (\"science_news\", \"quizzical_goldstine\")\n",
    "ondemand_feature_variant = (\"science_news_search\", \"quizzical_goldstine\")\n",
    "\n",
    "features = client.features(\n",
    "    [(ondemand_feature_variant)],\n",
    "    {\"link\": \"\"},\n",
    "    params=[query, embedding_feature_variant],\n",
    ")\n",
    "\n",
    "df = features[0]\n",
    "results = \"\\n\".join(\n",
    "    [\n",
    "        url\n",
    "        for url in df[\n",
    "            f\"{ondemand_feature_variant[0]}.{ondemand_feature_variant[1]}\"\n",
    "        ].values[0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"SEARCH RESULTS:\\n{results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.apply()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
