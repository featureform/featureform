name: Testing
on:
  push:
    branches:
      - main
      - release/*
  pull_request:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  MEILISEARCH_PORT: 7700
  MEILISEARCH_API_KEY: ""
  REDISEARCH_INSECURE_PORT: 6380
  REDIS_INSECURE_PORT: 6379
  REDIS_SECURE_PORT: 6378
  REDIS_PASSWORD: "password"
  CASSANDRA_USER: "cassandra"
  CASSANDRA_PASSWORD: "CASSANDRA"
  POSTGRES_USER: "username"
  POSTGRES_DB: "default"
  POSTGRES_PASSWORD: "password"
  CLICKHOUSE_USER: "default"
  CLICKHOUSE_HOST: "localhost"
  CLICKHOUSE_PASSWORD: "password"
  CLICKHOUSE_DB: "default"
  CLICKHOUSE_PORT: "9001"
  ETCD_HOST: "localhost"
  ETCD_PORT: 2379
  REDSHIFT_PORT: 5439
  REDSHIFT_DATABASE: dev
  SPARK_LOCAL_SCRIPT_PATH: scripts/spark/offline_store_spark_runner.py
  PYTHON_LOCAL_INIT_PATH: scripts/spark/python_packages.sh
  PINECONE_PROJECT_ID: ${{ secrets.PINECONE_PROJECT_ID }}
  PINECONE_ENVIRONMENT: ${{ secrets.PINECONE_ENVIRONMENT }}
  PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}

jobs:
  go-tests:
    name: Run Go Tests
    defaults:
      run:
        working-directory: ./
    runs-on: ubuntu-latest
    timeout-minutes: 120
    environment: Integration testing
    services:
#      redis-insecure:
#        image: redis
#        # Hard coded port because environment variables not currently
#        # supported for use outside of 'steps'
#        ports:
#          - 6379:6379

      cassandra:
        image: cassandra
        # Hard coded port because environment variables not currently
        # supported for use outside of 'steps'
        ports:
          - 9042:9042

      redisearch:
        image: redis/redis-stack
        # Hard coded port because environment variables not currently
        # supported for use outside of 'steps'
        ports:
          - 6379:6379
      postgres:
        image: postgres
        ports:
          - 5432:5432
        env:
          POSTGRES_USER: ${{ env.POSTGRES_USER }}
          POSTGRES_DB: ${{ env.POSTGRES_DB }}
          POSTGRES_PASSWORD: ${{ env.POSTGRES_PASSWORD }}

      clickhouse:
        image: clickhouse/clickhouse-server
        ports:
          - 9001:9000
        env:
          CLICKHOUSE_USER: ${{ env.CLICKHOUSE_USER }}
          CLICKHOUSE_DB: ${{ env.CLICKHOUSE_DB }}
          CLICKHOUSE_PASSWORD: ${{ env.CLICKHOUSE_PASSWORD }}
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip' # caching pip dependencies

      - name: Check directory
        run: |
          ls -la

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.21'
          check-latest: true
          cache-dependency-path: |
            go.sum

      - name: Install grpc_tools
        run: pip install grpcio-tools build

      - name: Install pyspark packages
        run: |
          pip install -r provider/scripts/k8s/requirements.txt
          pip install -r provider/scripts/spark/requirements.txt

      - name: Install Protobuf
        run: sudo snap install protobuf --classic

      - name: Setup Proto
        run: ./gen_grpc.sh

      - name: Unit Tests
        run: go test ./... -short

      - name: Install Search Container
        run: docker pull getmeili/meilisearch:v1.0

      - name: Start Search
        run: |
          docker run -d -p $MEILISEARCH_PORT:7700 getmeili/meilisearch:v1.0

      - uses: getong/redis-action@v1
        with:
          host port: 6378
          container port: 6379
          redis password: "password"

      - name: create-json
        id: create-json
        uses: jsdaniell/create-json@1.1.2
        with:
          name: "./provider/firestore_credentials.json"
          json: ${{ secrets.FIRESTORE_CREDENTIALS_FILE }}

      - name: create-json
        id: create-json-2
        uses: jsdaniell/create-json@1.1.2
        with:
          name: "./provider/bigquery_credentials.json"
          json: ${{ secrets.BIGQUERY_CREDENTIALS_FILE }}

      - name: Check credentials location
        run: |
          ls
          ls provider
          pwd

      - name: Install ETCD
        run: |
          git clone -b v3.4.16 https://github.com/etcd-io/etcd.git
          cd etcd
          ./build
          export PATH="$PATH:`pwd`/bin"
          etcd --version
          etcd --logger=zap &
          

      - name: Run HDFS
        run: |
          # git clone https://github.com/rancavil/hadoop-single-node-cluster.git
          # cd hadoop-single-node-cluster
          # docker build -t hadoop .
          docker run -d -p 9864:9864 -p 9870:9870 -p 8088:8088 -p 9000:9000 -p 9866:9866 --hostname localhost ahmadnazeri/hadoop:latest

      - name: Integration Tests
        run: go test -v -timeout 20m -parallel 1000 -coverpkg=./... -coverprofile=./cover.out.tmp ./...
        env:
          DYNAMO_ACCESS_KEY: ${{ secrets.AWS_ACCESS_KEY_ID }}
          DYNAMO_SECRET_KEY: ${{ secrets.AWS_SECRET_KEY }}
          DYNAMODB_REGION: "us-east-1"
          FIRESTORE_CRED: "firestore_credentials.json"
          FIRESTORE_PROJECT: ${{ secrets.FIRESTORE_PROJECT }}
          AZURE_ACCOUNT_NAME: ${{ secrets.AZURE_ACCOUNT_NAME }}
          AZURE_ACCOUNT_KEY: ${{ secrets.AZURE_ACCOUNT_KEY }}
          AZURE_CONTAINER_NAME: ${{ secrets.AZURE_CONTAINER_NAME }}
          AZURE_BACKUP_STORAGE_PATH: "backup"
          MONGODB_HOST: ${{ secrets.MONGODB_HOST }}
          MONGODB_PORT: ${{ secrets.MONGODB_PORT }}
          MONGODB_USERNAME: ${{ secrets.MONGODB_USERNAME }}
          MONGODB_PASSWORD: ${{ secrets.MONGODB_PASSWORD }}
          MONGODB_DATABASE: ${{ secrets.MONGODB_DATABASE }}
          SNOWFLAKE_USERNAME: ${{ secrets.SNOWFLAKE_USERNAME }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_ORG: ${{ secrets.SNOWFLAKE_ORG }}
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          REDSHIFT_USERNAME: ${{ secrets.REDSHIFT_USERNAME }}
          REDSHIFT_PASSWORD: ${{ secrets.REDSHIFT_PASSWORD }}
          REDSHIFT_HOST: ${{ secrets.REDSHIFT_HOST }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_KEY: ${{ secrets.AWS_SECRET_KEY }}
          AWS_EMR_CLUSTER_REGION: ${{ secrets.AWS_EMR_CLUSTER_REGION }}
          AWS_EMR_CLUSTER_ID: ${{ secrets.AWS_EMR_CLUSTER_ID }}
          S3_BUCKET_PATH: ${{ secrets.S3_BUCKET_PATH }}
          S3_BUCKET_REGION: ${{ secrets.S3_BUCKET_REGION }}
          BIGQUERY_PROJECT_ID: ${{ secrets.BIGQUERY_PROJECT_ID }}
          BIGQUERY_DATASET_ID: ${{ secrets.BIGQUERY_DATASET_ID }}
          BIGQUERY_CREDENTIALS: "/home/runner/work/featureform/featureform/provider/bigquery_credentials.json"
          MYSQL_USER: "root"
          MYSQL_PASSWORD: "password"
          MYSQL_DB: "mysql"
          AZURE_CONTAINER_PATH: ${{ secrets.AZURE_CONTAINER_PATH }}
          AZURE_CONNECTION_STRING: ${{ secrets.AZURE_CONNECTION_STRING }}
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          DATABRICKS_CLUSTER: ${{ secrets.DATABRICKS_CLUSTER }}
          MATERIALIZE_NO_TIMESTAMP_QUERY_PATH: /home/runner/work/featureform/featureform/provider/queries/materialize_no_ts.sql
          MATERIALIZE_WITH_TIMESTAMP_QUERY_PATH: /home/runner/work/featureform/featureform/provider/queries/materialize_ts.sql
          ETCD_HOST: ${{ env.ETCD_HOST }}
          ETCD_PORT: ${{ env.ETCD_PORT }}
          SPARK_LOCAL_SCRIPT_PATH: /home/runner/work/featureform/featureform/provider/scripts/spark/offline_store_spark_runner.py
          PYTHON_LOCAL_INIT_PATH: /home/runner/work/featureform/featureform/provider/scripts/spark/python_packages.sh

      - name: Print Clean Coverage
        if: always()
        run: |
          cat cover.out.tmp | grep -v "proto" | grep -v "main"  > cover.out
          go tool cover -html=cover.out -o cover.html

      - name: Archive code coverage results (HTML)
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: go-coverage-html
          path: ./cover.html

      - name: Archive code coverage results (cover.out)
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: go-coverage-out
          path: ./cover.out

  client-deps:
    name: Client Dependencies
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Check directory
        run: |
          ls -la

      - name: Set up Go
        uses: actions/setup-go@v2
        with:
          go-version: 1.21

      - name: Install grpc_tools
        run: pip install grpcio-tools build

      - name: Install Protobuf
        run: sudo snap install protobuf --classic

      - name: Setup Proto
        run: ./gen_grpc.sh

      - name: Build Python Package
        run: ./pip_update.sh --no-dash

      - uses: actions/upload-artifact@v3
        with:
          name: client
          path: ./client
          retention-days: 1

  client:
    name: Test Client
    needs: client-deps
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ["3.7", "3.8", "3.9", "3.10", "3.11"]
        exclude:
          - os: windows-latest
            python-version: "3.11"
    steps:
      - uses: actions/checkout@v2

      - name: Download Working Compiled Directories
        uses: actions/download-artifact@v3
        with:
          name: client
          path: ./client

      - run: ls

      #
      # https://github.com/actions/setup-python/issues/682
      # Python 3.7.17 in MacOSX will raise "No module named _bz2" exception, so pinning to 3.7.16
      #
      # Previous setup, revert back to the below once th3 issue is fixed:
      # - name: Set up Python
      #   uses: actions/setup-python@v4
      #   with:
      #     python-version: ${{ matrix.python-version }}
      #
      - uses: actions/setup-python@v4
        if: matrix.os != 'macos-latest' || ( matrix.os == 'macos-latest' && matrix.python-version != '3.7' )
        with:
          python-version: ${{ matrix.python-version }}


      - uses: actions/setup-python@v4
        if: matrix.os == 'macos-latest' && matrix.python-version == '3.7'
        with:
          python-version: "3.7.16"

      - name: Install pyspark packages
        run: |
          pip install -r provider/scripts/k8s/requirements.txt
          pip install -r provider/scripts/spark/requirements.txt

      - name: Install pytest
        run: pip install -r pytest-requirements.txt

      - name: Install pytest cov
        run: pip install pytest-cov

      - name: Install featureform
        run: pip install client/dist/featureform-0.0.0-py3-none-any.whl

      - name: Run Tests
        run: pytest -vv -s

      - uses: actions/upload-artifact@v3
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.10'
        with:
          name: client-coverage
          path: ./coverage.xml
          retention-days: 1

  dashboard:
    name: Test Dashboard
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./dashboard
    steps:
      - uses: actions/checkout@v2

      - uses: actions/setup-node@v4
        with:
          node-version: '16'

      - name: Install Packages
        run: npm install

      - name: Install Jest
        run: npm install jest

      - name: Run Tests
        run: ./node_modules/.bin/jest --coverage

      - uses: actions/upload-artifact@v3
        with:
          name: dashboard-coverage
          path: ./dashboard/coverage/clover.xml
          retention-days: 1

  codecov-upload:
    name: Codecov Upload
    needs: [client, go-tests, dashboard]
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Download Client Coverage
        uses: actions/download-artifact@v3
        with:
          name: client-coverage

      - name: Download Go Coverage
        uses: actions/download-artifact@v3
        with:
          name: go-coverage-out

      - name: Download Go Coverage
        uses: actions/download-artifact@v3
        with:
          name: dashboard-coverage

      - uses: codecov/codecov-action@v4
        with:
          files: ./coverage.xml,./cover.out,./clover.xml
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
          verbose: true


